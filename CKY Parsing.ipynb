{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef5e459-6e06-4437-8fcd-c8980202c8a0",
   "metadata": {},
   "source": [
    "# The CKY Algorithm and Syntactic Parsing\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "Today's activity will be to implement CKY parsing \n",
    "\n",
    "#### Getting Started\n",
    "\n",
    "As you saw in the reading, in order to apply a parsing technique like CKY, we need to have grammars in a very particular form: *Chomsky-Normal Form*, or *CNF*. CNF Grammars are constrained insofar as they can only contain two kinds of rules:\n",
    "\n",
    "1. Rules of the form $A \\rightarrow B C$, which I will call *Grammar Rules*, which allow a nonterminal $A \\in N$ to expand to two nonterminals $B, C \\in N$.\n",
    "2. Rules of the form $A \\rightarrow w$, which I will call *Lexical Rules*, which allow a nonterminal $A \\in N$ to expand to a single terminal $w \\in \\Sigma$.\n",
    "\n",
    "Now, for the purposes of time, I won't ask you to write an algorithm to convert any CFG to CNF (though you can do that, and J&M explain the key ideas in 18.6.1, which I'll expect you to know!) However, I will introduce a new Grammar class that enforces the CNF constraints, `CNFGrammar`. \n",
    "\n",
    "To understand how it's structured, I'd like you to write two methods for the class:\n",
    "1. Write `merges_to`, which, given $B, C \\in N$, returns a list of nonterminals that can expand to $B$ $C$ under the grammar (i.e., through a grammar rule). \n",
    "2. Write `tag`, which, given $w \\in \\Sigma$, returns a list of nonterminals that can expand to $w$ (i.e., through a lexical rule).\n",
    "\n",
    "**Make sure you understand how the grammar is structured before moving on**.\n",
    "\n",
    "Note that the representation of the grammar is not optimized for `merges_to` and `tag` to run as efficiently as they could. As a **bonus** you can restructure how `LR` and `GR` are structured to do that optimization, but do that after completing everything else: We're just seeking the standard CKY asymptotic complexity of $O(n^3)$, with $n$ being the length of the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572794a5-ad2d-4b56-9bdf-2ebcc9b6abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Sequence, Mapping, Tuple\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class CNFGrammar:\n",
    "    def __init__(self,\n",
    "                 S : str, \n",
    "                 T : Iterable[str], \n",
    "                 NT : Iterable[str], \n",
    "                 LR : Mapping[str, Sequence[str]],\n",
    "                 GR : Mapping[str, Sequence[Sequence[str]]]):\n",
    "        self.S = S\n",
    "        self.T = T\n",
    "        self.NT = NT\n",
    "        self.LR = LR\n",
    "        self.GR = GR\n",
    "\n",
    "    def get_start(self) -> str:\n",
    "        return self.S\n",
    "        \n",
    "    def print_rules(self) -> None:\n",
    "        print(\"---Lexical Rules\")\n",
    "        for lhs, rhss in self.LR.items():\n",
    "            print(\"{} -> {}\".format(lhs, \", \".join(rhss)))\n",
    "        print(\"---Grammar Rules\")\n",
    "        for lhs, rhss in self.GR.items():\n",
    "            for rhs in rhss:\n",
    "                print(\"{} -> {}\".format(lhs, \" \".join(rhs)))\n",
    "\n",
    "    def merges_to(self, B : str, C : str) -> Iterable[str]:\n",
    "        # TODO: return a list of all NTs A such that \n",
    "        # A -> B C is in the grammar\n",
    "        out = []\n",
    "        return out\n",
    "\n",
    "    def tag(self, a : str) -> Sequence[str]:\n",
    "        # TODO: return a list of all NTs A such that\n",
    "        # A -> a is in the grammar\n",
    "        out = []\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd56e0-cbac-4168-b0c5-31719201be39",
   "metadata": {},
   "source": [
    "Below is the CNF Grammar from Figure 18.10 from the J&M. Use the next two cells to confirm that your implementations are working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627f2d0-515c-48f6-8574-f11d9f38f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the J&M Reading\n",
    "\n",
    "S = \"S\"\n",
    "T = set([\"book\", \"flight\", \"meal\", \"money\", \"include\",\n",
    "     \"prefer\", \"does\",\n",
    "     \"me\", \"I\", \"she\",\n",
    "     \"Houston\", \"NWA\",\n",
    "     \"the\", \"a\", \"this\", \"that\",\n",
    "     \"from\", \"to\", \"on\", \"near\", \"through\"])\n",
    "NT = set([\"N\", \"V\", \"X1\", \"X2\", \"D\", \"P\", \"Aux\", \"S\", \"NP\", \"Nom\", \"VP\", \"PP\"])\n",
    "LR = {\n",
    "        # Lexical Rules\n",
    "        \"N\": [\"book\", \"flight\", \"meal\", \"money\"],\n",
    "        \"V\": [\"book\", \"include\", \"prefer\"],\n",
    "        \"D\": [\"the\", \"a\", \"that\", \"this\"],\n",
    "        \"P\": [\"from\", \"to\", \"on\", \"near\", \"through\"],\n",
    "        \"Conj\": [\"and\", \"or\", \"but\"],\n",
    "        \"Aux\": [\"does\"],\n",
    "        \"NP\":[\"me\", \"she\", \"I\", \"Houston\", \"NWA\"],\n",
    "        \"Nom\":[\"book\", \"flight\", \"meal\", \"money\"],\n",
    "        \"VP\":[\"book\", \"include\", \"prefer\"],\n",
    "        \"S\":[\"book\", \"include\", \"prefer\"]\n",
    "}\n",
    "GR = {\n",
    "        # Grammar Rules\n",
    "        \"S\":[[\"NP\", \"VP\"],\n",
    "             [\"X1\", \"VP\"],\n",
    "             [\"V\", \"NP\"],\n",
    "             [\"X2\", \"PP\"],\n",
    "             [\"V\", \"PP\"],\n",
    "             [\"VP\", \"PP\"]],\n",
    "        \"X1\":[[\"Aux\", \"NP\"]],\n",
    "        \"NP\":[[\"D\", \"Nom\"]],\n",
    "        \"Nom\":[[\"Nom\", \"N\"], \n",
    "               [\"Nom\", \"PP\"]],\n",
    "        \"VP\":[[\"V\", \"NP\"], \n",
    "              [\"X2\", \"PP\"],\n",
    "              [\"V\", \"PP\"]],\n",
    "        \"X2\":[[\"V\", \"NP\"]],\n",
    "        \"PP\":[[\"P\", \"NP\"]]\n",
    "}\n",
    "\n",
    "JMGrammar = CNFGrammar(S, T, NT, LR, GR)\n",
    "JMGrammar.print_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f045d-b010-4dd6-b735-9e72a973d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(JMGrammar.merges_to(\"D\", \"Nom\")) # Should be [NP]\n",
    "print(JMGrammar.tag(\"book\")) # Should be [N, V, Nom, VP, S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9dcb3-d1ea-46f2-adad-7e45781e7748",
   "metadata": {},
   "source": [
    "#### Implementing CKY Recognition\n",
    "\n",
    "Now time to implement the CKY algorithm yourself! \n",
    "\n",
    "Remember that we...\n",
    "1. Tag each word with possible nonterminals using lexical rules and store the results along the main diagonal of our chart.\n",
    "2. For each size of constituent/*span*, from smallest to largest...\n",
    "    1. For each span of that size...\n",
    "       1. For each way to split that span into two halves...\n",
    "          1. We check the grammar to see whether the two halves of the split can merge into a larger nonterminal via a Grammar Rule (check the corresponding cells for those smaller halves to see what nonterminals they can be!). We add these to the cell corresponding to the full constituent.\n",
    "3. You have one cell in the chart corresponding to the full sentence --- which one?) If the start symbol is contained in that cell, the sentence is grammatical!\n",
    "\n",
    "I recommend implementing your code so that it mirrors how you'd implement the algorithm by hand! If you *don't* know how you'd implement it by hand, I would recommend stepping through the example from the reading with your partner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bf929-aee3-4226-910b-1e85f3f594b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printChart(chart : Iterable[Iterable[Iterable[str]]]) -> None:\n",
    "    # May be useful for debugging your chart\n",
    "    for i in range(len(chart)):\n",
    "        print(\"\\t\".join([str(x).ljust(20) for x in chart[i]]))\n",
    "\n",
    "def CKYRecognizer(grammar : CNFGrammar, sent : Sequence[str]) -> bool:\n",
    "    # TODO: Implement the CKY algorithm\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb631951-8b24-4f1b-867d-d3008068ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKYRecognizer(JMGrammar, \"book the flight through Houston\".split()) # Should be grammatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d5cb1-741c-4a47-8954-68272cde69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKYRecognizer(JMGrammar, \"Houston the book flight through\".split()) # Should be ungrammatical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36829ff-474d-4811-92e3-52c7dd17c2ca",
   "metadata": {},
   "source": [
    "#### Implementing Full Parsing\n",
    "\n",
    "Now, with some additional time, we can do something I find pretty cool: full *parsing*, where we reconstruct the parse tree that would generate the sentence. The way we do this is by adding in some additional book-keeping: Every time we determine a span can form a constituent with a particular non-terminal label (i.e., \"through Houston\" is a PP), we store not just the non-terminal, but information that lets us know exactly which the two subpieces that got us there. In fact, if we want to be a bit extravagant, we can store the *entire parse tree* that gets us from the string of terminals within the constituent to the nonterminal label. \n",
    "\n",
    "In practice, this is a bit unnecessary and terribly inefficient (it's much better to use the textbook's recommendation and store backpointers to elsewhere in the table). Pedagogically (and for the small examples we consider here), it works out a lot more cleanly, so we'll do that here. Though, again, as a **bonus**, you can write a more memory-efficient version!\n",
    "\n",
    "Here's what you should do:\n",
    "1. Look at the example code for NLTK's `Tree` class to see how you should can build the relevant tree.\n",
    "2. Write `CKYParser` below so that it returns a *list* of valid parse trees. If the sentence is ambiguous, you should return *all* trees that represent that ambiguity!\n",
    "3. Bask in the beautiful parse tree's you've generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469b956-7d22-4f6f-95ec-d3b2d82ac68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "\n",
    "B = Tree(\"D\", [\"the\"])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7ce33-7cb1-43a3-ad7b-60a03a50bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Tree(\"Nom\", [\"flight\"])\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c375c-5c8c-4e04-927d-29432721ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Tree(\"NP\", [B, C])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b77a8-1510-4ecd-ad26-6e2f3faf7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CKYParser(grammar : CNFGrammar, sent : Sequence[str]) -> Sequence[Tree]:\n",
    "    # TODO: Update your Recognizer code from above to build parse trees\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43244a01-aa0f-42a2-911a-2d783f7fd3ee",
   "metadata": {},
   "source": [
    "If all goes well, you'll get 3 parse trees below! One that begins with $\\text{S} \\rightarrow \\text{V NP}$, another that begins with $\\text{S} \\rightarrow \\text{VP PP}$, and the last that begins with the rule $\\text{S} \\rightarrow \\text{X2 NP}$.\n",
    "\n",
    "Wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cd15e-7ec4-4aee-af97-30af6da095d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "parses = CKYParser(JMGrammar, \"book the flight through Houston\".split())\n",
    "\n",
    "for parse in parses:\n",
    "    display(parse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
